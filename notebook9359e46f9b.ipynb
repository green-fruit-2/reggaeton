{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-14T14:11:51.028456Z","iopub.execute_input":"2022-07-14T14:11:51.029009Z","iopub.status.idle":"2022-07-14T14:11:51.067081Z","shell.execute_reply.started":"2022-07-14T14:11:51.028902Z","shell.execute_reply":"2022-07-14T14:11:51.066125Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"lyrics = pd.read_csv(\"/kaggle/input/bad-bunny-lyrics/bad_bunny_lyrics.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:11:51.068738Z","iopub.execute_input":"2022-07-14T14:11:51.069041Z","iopub.status.idle":"2022-07-14T14:11:51.091175Z","shell.execute_reply.started":"2022-07-14T14:11:51.069017Z","shell.execute_reply":"2022-07-14T14:11:51.090091Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Good regex resource: https://realpython.com/regex-python/#python-regex-metacharacters\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:11:51.092708Z","iopub.execute_input":"2022-07-14T14:11:51.093152Z","iopub.status.idle":"2022-07-14T14:11:51.097471Z","shell.execute_reply.started":"2022-07-14T14:11:51.093120Z","shell.execute_reply":"2022-07-14T14:11:51.096429Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# practice_str = '[Letra de \"NI BIEN NI MAL\"]  [Intro: Bad Bunny] Yeh-yeh Yeh-yeh Yeh-yeh'\npractice_song_lyric = lyrics.iloc[0,4]\npractice_song_lyric","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:12:08.773571Z","iopub.execute_input":"2022-07-14T14:12:08.773954Z","iopub.status.idle":"2022-07-14T14:12:08.787715Z","shell.execute_reply.started":"2022-07-14T14:12:08.773923Z","shell.execute_reply":"2022-07-14T14:12:08.786615Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(practice_song_lyric)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:20:47.326370Z","iopub.execute_input":"2022-07-14T14:20:47.326769Z","iopub.status.idle":"2022-07-14T14:20:47.331747Z","shell.execute_reply.started":"2022-07-14T14:20:47.326736Z","shell.execute_reply":"2022-07-14T14:20:47.330840Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Source: https://stackoverflow.com/questions/65022050/cleaning-song-lyrics-with-regex","metadata":{"execution":{"iopub.status.busy":"2022-07-13T15:33:03.398902Z","iopub.execute_input":"2022-07-13T15:33:03.399306Z","iopub.status.idle":"2022-07-13T15:33:03.407217Z","shell.execute_reply.started":"2022-07-13T15:33:03.399276Z","shell.execute_reply":"2022-07-13T15:33:03.405975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removed brackets used to denote sections of song\n# removed new lines and added periods for sentence tokenization\nremoved_brackets = re.sub(r\"[\\[].*?[\\]]\",\"\",practice_song_lyric)\nno_brackets_or_new_lines = re.sub(r\"\\n{2}\",\"\",removed_brackets)\nno_brackets_or_new_lines = re.sub(r\"[\\n]\",\". \",no_brackets_or_new_lines)\nprint(no_brackets_or_new_lines)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:59:32.452897Z","iopub.execute_input":"2022-07-14T14:59:32.453266Z","iopub.status.idle":"2022-07-14T14:59:32.458788Z","shell.execute_reply.started":"2022-07-14T14:59:32.453237Z","shell.execute_reply":"2022-07-14T14:59:32.458040Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# might need to replace new lines with periods\ncorrect_vas = re.sub(r\"va\\'\",\"vas\",no_brackets_or_new_lines)\ncorrect_para_zero = re.sub(r\"Pa\\'l\",\"Para el\",correct_vas)\ncorrect_para = re.sub(r\"Pa\\'\",\"Para \",correct_para_zero)\ncorrect_voy = re.sub(r\"vo\\'\",\"voy \",correct_para)\ncorrect_para_2 = re.sub(r\"pa\\'\",\"para\",correct_voy)\ncorrect_de = re.sub(r\"\\'e\",\"de\",correct_para_2)\ncorrect_puyas = re.sub(r\"puya\\'\",\"puyas\",correct_de)\ncorrect_puyas += '.'\ncorrect_puyas","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:59:36.396487Z","iopub.execute_input":"2022-07-14T14:59:36.396844Z","iopub.status.idle":"2022-07-14T14:59:36.406402Z","shell.execute_reply.started":"2022-07-14T14:59:36.396816Z","shell.execute_reply":"2022-07-14T14:59:36.405329Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"0. Sentence Tokenization\n0. Finding semantically related words using word embeddings (already loadded the dataset)\n0. Spanish lemmatizer - https://stackoverflow.com/questions/60534999/how-to-solve-spanish-lemmatization-problems-with-spacy\n    * The link above has sources that show how to make your own lemmatizer, FreeLing (provides lemmatization in Spanish and other languages), and spacy-stanza (\"spaCy's API with the Stanza's models\")\n    * https://github.com/pablodms/spacy-spanish-lemmatizer     \n0. Word Cloud\n1. Topic Modeling - can later let the user generate songs based on a topic\n2. Sentiment Analysis - user can create songs with a specific sentiment\n    * Spanish Sentiment Analyis [Library](https://pypi.org/project/sentiment-analysis-spanish/) (uses CNN).","metadata":{}},{"cell_type":"code","source":"!pip install stanza ","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:47:02.407066Z","iopub.execute_input":"2022-07-14T14:47:02.407470Z","iopub.status.idle":"2022-07-14T14:47:17.068649Z","shell.execute_reply.started":"2022-07-14T14:47:02.407434Z","shell.execute_reply":"2022-07-14T14:47:17.067565Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Source: https://stanfordnlp.github.io/stanza/\n# Source: https://stanfordnlp.github.io/stanza/tokenize.html#:~:text=Training%2DOnly%20Options-,Description,invoked%20by%20the%20name%20tokenize%20.\n# Note: Stanza does not offer a Spanish Sentiment Analyzer\n# Check out Stanza's other sections like:\n# - Pipeline and Processors\n# - Part-of-Speech and Morphological Features\n# - Lemmatization\nimport stanza","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:50:22.394336Z","iopub.execute_input":"2022-07-14T14:50:22.394795Z","iopub.status.idle":"2022-07-14T14:50:33.735565Z","shell.execute_reply.started":"2022-07-14T14:50:22.394751Z","shell.execute_reply":"2022-07-14T14:50:33.734216Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"stanza.download('es', package='ancora', processors='tokenize,mwt,pos,lemma', verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:50:35.590169Z","iopub.execute_input":"2022-07-14T14:50:35.591078Z","iopub.status.idle":"2022-07-14T14:50:39.795969Z","shell.execute_reply.started":"2022-07-14T14:50:35.591046Z","shell.execute_reply":"2022-07-14T14:50:39.794445Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma', lang='es', use_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T15:20:59.946764Z","iopub.execute_input":"2022-07-14T15:20:59.947151Z","iopub.status.idle":"2022-07-14T15:21:00.717108Z","shell.execute_reply.started":"2022-07-14T15:20:59.947122Z","shell.execute_reply":"2022-07-14T15:21:00.716080Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"doc = stNLP('Barack Obama naci√≥ en Hawaii.')\nprint(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:51:08.643158Z","iopub.execute_input":"2022-07-14T14:51:08.643616Z","iopub.status.idle":"2022-07-14T14:51:08.749064Z","shell.execute_reply.started":"2022-07-14T14:51:08.643579Z","shell.execute_reply":"2022-07-14T14:51:08.747650Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Source: https://stanfordnlp.github.io/stanza/tokenize.html#:~:text=Training%2DOnly%20Options-,Description,invoked%20by%20the%20name%20tokenize%20.\n# tokenization and sentence segmentation performed\ndoc = stNLP(correct_puyas)","metadata":{"execution":{"iopub.status.busy":"2022-07-14T14:59:44.386383Z","iopub.execute_input":"2022-07-14T14:59:44.386748Z","iopub.status.idle":"2022-07-14T14:59:45.507078Z","shell.execute_reply.started":"2022-07-14T14:59:44.386716Z","shell.execute_reply":"2022-07-14T14:59:45.506183Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for i, sentence in enumerate(doc.sentences[4:6]):\n    print(f'====== Sentence {i+1} tokens =======')\n    print(*[f'id: {token.id}\\ttext: {token.text}' for token in sentence.tokens], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-14T15:07:43.274789Z","iopub.execute_input":"2022-07-14T15:07:43.275269Z","iopub.status.idle":"2022-07-14T15:07:43.282780Z","shell.execute_reply.started":"2022-07-14T15:07:43.275231Z","shell.execute_reply":"2022-07-14T15:07:43.281745Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print([sentence.text for sentence in doc.sentences[4:6]])","metadata":{"execution":{"iopub.status.busy":"2022-07-14T15:08:19.443735Z","iopub.execute_input":"2022-07-14T15:08:19.444207Z","iopub.status.idle":"2022-07-14T15:08:19.450655Z","shell.execute_reply.started":"2022-07-14T15:08:19.444170Z","shell.execute_reply":"2022-07-14T15:08:19.449686Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"doc.sentences[4:5]","metadata":{"execution":{"iopub.status.busy":"2022-07-14T15:00:06.826895Z","iopub.execute_input":"2022-07-14T15:00:06.827327Z","iopub.status.idle":"2022-07-14T15:00:06.836513Z","shell.execute_reply.started":"2022-07-14T15:00:06.827291Z","shell.execute_reply":"2022-07-14T15:00:06.835454Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# replaces all Unicode whitespace (such as \\u) with a single space\n#re.sub(\"\\s+\", \" \", lyric, flags=re.UNICODE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spanish lemmatization (pattern)\n# Spanish word normalization Python packages and libraries (Cucco)\n# ftfy - handles mojibake\n# Tokenize - nltk package (tokenize and FreqDist)","metadata":{},"execution_count":null,"outputs":[]}]}