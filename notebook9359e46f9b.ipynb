{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-18T18:20:08.280521Z","iopub.execute_input":"2022-07-18T18:20:08.281975Z","iopub.status.idle":"2022-07-18T18:20:08.316636Z","shell.execute_reply.started":"2022-07-18T18:20:08.281928Z","shell.execute_reply":"2022-07-18T18:20:08.315587Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"lyrics = pd.read_csv(\"/kaggle/input/bad-bunny-lyrics/bad_bunny_lyrics.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:08.623310Z","iopub.execute_input":"2022-07-18T18:20:08.623751Z","iopub.status.idle":"2022-07-18T18:20:08.654586Z","shell.execute_reply.started":"2022-07-18T18:20:08.623721Z","shell.execute_reply":"2022-07-18T18:20:08.653710Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Good regex resource: https://realpython.com/regex-python/#python-regex-metacharacters\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:10.113277Z","iopub.execute_input":"2022-07-18T18:20:10.113769Z","iopub.status.idle":"2022-07-18T18:20:10.118988Z","shell.execute_reply.started":"2022-07-18T18:20:10.113729Z","shell.execute_reply":"2022-07-18T18:20:10.117753Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# practice_str = '[Letra de \"NI BIEN NI MAL\"]  [Intro: Bad Bunny] Yeh-yeh Yeh-yeh Yeh-yeh'\npractice_song_lyric = lyrics.iloc[0,4]\npractice_song_lyric","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:10.702295Z","iopub.execute_input":"2022-07-18T18:20:10.703172Z","iopub.status.idle":"2022-07-18T18:20:10.713584Z","shell.execute_reply.started":"2022-07-18T18:20:10.703097Z","shell.execute_reply":"2022-07-18T18:20:10.712478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(practice_song_lyric)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:13.540125Z","iopub.execute_input":"2022-07-18T18:20:13.540583Z","iopub.status.idle":"2022-07-18T18:20:13.548468Z","shell.execute_reply.started":"2022-07-18T18:20:13.540550Z","shell.execute_reply":"2022-07-18T18:20:13.547076Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Source: https://stackoverflow.com/questions/65022050/cleaning-song-lyrics-with-regex","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:16.087005Z","iopub.execute_input":"2022-07-18T18:20:16.088197Z","iopub.status.idle":"2022-07-18T18:20:16.093029Z","shell.execute_reply.started":"2022-07-18T18:20:16.088123Z","shell.execute_reply":"2022-07-18T18:20:16.091830Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# removed brackets used to denote sections of song\n# removed new lines and added periods for sentence tokenization\nremoved_brackets = re.sub(r\"[\\[].*?[\\]]\",\"\",practice_song_lyric)\nno_brackets_or_new_lines = re.sub(r\"\\n{2}\",\"\",removed_brackets)\nno_brackets_or_new_lines = re.sub(r\"[\\n]\",\". \",no_brackets_or_new_lines)\nprint(no_brackets_or_new_lines)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:16.304107Z","iopub.execute_input":"2022-07-18T18:20:16.304986Z","iopub.status.idle":"2022-07-18T18:20:16.311773Z","shell.execute_reply.started":"2022-07-18T18:20:16.304948Z","shell.execute_reply":"2022-07-18T18:20:16.310629Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# might need to replace new lines with periods\ncorrect_vas = re.sub(r\"va\\'\",\"vas\",no_brackets_or_new_lines)\ncorrect_para_zero = re.sub(r\"Pa\\'l\",\"Para el\",correct_vas)\ncorrect_para = re.sub(r\"Pa\\'\",\"Para \",correct_para_zero)\ncorrect_voy = re.sub(r\"vo\\'\",\"voy \",correct_para)\ncorrect_para_2 = re.sub(r\"pa\\'\",\"para\",correct_voy)\ncorrect_de = re.sub(r\"\\'e\",\"de\",correct_para_2)\ncorrect_puyas = re.sub(r\"puya\\'\",\"puyas\",correct_de)\ncorrect_puyas += '.'\ncorrect_puyas","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:16.776469Z","iopub.execute_input":"2022-07-18T18:20:16.777580Z","iopub.status.idle":"2022-07-18T18:20:16.787832Z","shell.execute_reply.started":"2022-07-18T18:20:16.777537Z","shell.execute_reply":"2022-07-18T18:20:16.786917Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!pip install stanza ","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:45.565765Z","iopub.execute_input":"2022-07-18T18:20:45.567004Z","iopub.status.idle":"2022-07-18T18:20:59.843781Z","shell.execute_reply.started":"2022-07-18T18:20:45.566946Z","shell.execute_reply":"2022-07-18T18:20:59.842535Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Source: https://stanfordnlp.github.io/stanza/\n# Source: https://stanfordnlp.github.io/stanza/tokenize.html#:~:text=Training%2DOnly%20Options-,Description,invoked%20by%20the%20name%20tokenize%20.\n# Note: Stanza does not offer a Spanish Sentiment Analyzer\n# Check out Stanza's other sections like:\n# - Pipeline and Processors\n# - Part-of-Speech and Morphological Features\n# - Lemmatization\nimport stanza","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:59.845788Z","iopub.execute_input":"2022-07-18T18:20:59.846198Z","iopub.status.idle":"2022-07-18T18:20:59.962669Z","shell.execute_reply.started":"2022-07-18T18:20:59.846156Z","shell.execute_reply":"2022-07-18T18:20:59.961372Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"stanza.download('es', package='ancora', processors='tokenize,mwt,pos,lemma', verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:20:59.964356Z","iopub.execute_input":"2022-07-18T18:20:59.964722Z","iopub.status.idle":"2022-07-18T18:21:19.777269Z","shell.execute_reply.started":"2022-07-18T18:20:59.964672Z","shell.execute_reply":"2022-07-18T18:21:19.775972Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma', lang='es', use_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:19.781019Z","iopub.execute_input":"2022-07-18T18:21:19.781523Z","iopub.status.idle":"2022-07-18T18:21:20.947990Z","shell.execute_reply.started":"2022-07-18T18:21:19.781466Z","shell.execute_reply":"2022-07-18T18:21:20.946845Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"doc = stNLP('Barack Obama nació en Hawaii.')\nprint(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:20.949652Z","iopub.execute_input":"2022-07-18T18:21:20.950138Z","iopub.status.idle":"2022-07-18T18:21:21.086876Z","shell.execute_reply.started":"2022-07-18T18:21:20.950088Z","shell.execute_reply":"2022-07-18T18:21:21.085651Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Source: https://stanfordnlp.github.io/stanza/tokenize.html#:~:text=Training%2DOnly%20Options-,Description,invoked%20by%20the%20name%20tokenize%20.\n# tokenization and sentence segmentation performed\ndoc = stNLP(correct_puyas)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:21.088842Z","iopub.execute_input":"2022-07-18T18:21:21.089937Z","iopub.status.idle":"2022-07-18T18:21:22.243601Z","shell.execute_reply.started":"2022-07-18T18:21:21.089891Z","shell.execute_reply":"2022-07-18T18:21:22.242293Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences[4:6] for word in sent.words], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:22.248066Z","iopub.execute_input":"2022-07-18T18:21:22.248656Z","iopub.status.idle":"2022-07-18T18:21:22.255340Z","shell.execute_reply.started":"2022-07-18T18:21:22.248621Z","shell.execute_reply":"2022-07-18T18:21:22.254280Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for i, sentence in enumerate(doc.sentences[4:6]):\n    print(f'====== Sentence {i+1} tokens =======')\n    print(*[f'id: {token.id}\\ttext: {token.text}' for token in sentence.tokens], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:22.256830Z","iopub.execute_input":"2022-07-18T18:21:22.257962Z","iopub.status.idle":"2022-07-18T18:21:22.272129Z","shell.execute_reply.started":"2022-07-18T18:21:22.257924Z","shell.execute_reply":"2022-07-18T18:21:22.270629Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print([sentence.text for sentence in doc.sentences[4:6]])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:22.273950Z","iopub.execute_input":"2022-07-18T18:21:22.275350Z","iopub.status.idle":"2022-07-18T18:21:22.290457Z","shell.execute_reply.started":"2022-07-18T18:21:22.275142Z","shell.execute_reply":"2022-07-18T18:21:22.289206Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"doc.sentences[4:5]","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:15.300856Z","iopub.execute_input":"2022-07-15T18:18:15.301281Z","iopub.status.idle":"2022-07-15T18:18:15.311779Z","shell.execute_reply.started":"2022-07-15T18:18:15.301258Z","shell.execute_reply":"2022-07-15T18:18:15.310914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replaces all Unicode whitespace (such as \\u) with a single space\n#re.sub(\"\\s+\", \" \", lyric, flags=re.UNICODE)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:15.312888Z","iopub.execute_input":"2022-07-15T18:18:15.314163Z","iopub.status.idle":"2022-07-15T18:18:15.320770Z","shell.execute_reply.started":"2022-07-15T18:18:15.314116Z","shell.execute_reply":"2022-07-15T18:18:15.319868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spanish word normalization Python packages and libraries (Cucco)\n# ftfy - handles mojibake","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:15.321852Z","iopub.execute_input":"2022-07-15T18:18:15.322556Z","iopub.status.idle":"2022-07-15T18:18:15.331485Z","shell.execute_reply.started":"2022-07-15T18:18:15.322527Z","shell.execute_reply":"2022-07-15T18:18:15.330476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0. Sentence Tokenization - nltk package (tokenize and FreqDist)\n0. Finding semantically related words using word embeddings (already loadded the dataset)\n    * Look at Google Colab book on word2vec to see an example of how to do this\n0. Spanish lemmatizer - https://stackoverflow.com/questions/60534999/how-to-solve-spanish-lemmatization-problems-with-spacy\n    * The link above has sources that show how to make your own lemmatizer, FreeLing (provides lemmatization in Spanish and other languages), and spacy-stanza (\"spaCy's API with the Stanza's models\")\n    * https://github.com/pablodms/spacy-spanish-lemmatizer    \n    * pattern is another library\n0. Word Cloud\n1. **Topic Modeling** - can later let the user generate songs based on a topic\n    * This might use zero-shot classification (which can be done in Hugging Face)\n2. **Sentiment Analysis** - user can create songs with a specific sentiment\n    * Another option for sentiment analysis: using pysentimiento for emotion analysis (in addition to sentiment analysis)\n    * Another option for sentiment analysis: using Big Science Bloom\n3. **Text Generation**\n    * Two GPT-2 Models\n3. Learn how to Use Kaggle Console effectively for projects\n4. **Quick Tour on HuggingFace Transformers**\n    * https://huggingface.co/docs/transformers/quicktour\n5. **Getting Started with HuggingFace**\n    * https://www.youtube.com/watch?v=QEaBAZQCtwE&t=120s","metadata":{}},{"cell_type":"markdown","source":"* How to track Jupyter notebook changes in GitHub - https://blog.reviewnb.com/jupyter-notebook-on-github-oss-examples/\n* Top 8 Python libraries for NLP - https://www.analyticsvidhya.com/blog/2021/05/top-8-python-libraries-for-natural-language-processing-nlp-in-2021/","metadata":{}},{"cell_type":"markdown","source":"# Sentiment Analysis (Library #1)","metadata":{}},{"cell_type":"code","source":"!pip install sentiment-analysis-spanish\n!pip install keras tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:37.551851Z","iopub.execute_input":"2022-07-15T18:18:37.552208Z","iopub.status.idle":"2022-07-15T18:19:16.258224Z","shell.execute_reply.started":"2022-07-15T18:18:37.552179Z","shell.execute_reply":"2022-07-15T18:19:16.257115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentiment_analysis_spanish import sentiment_analysis","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:19:16.260857Z","iopub.execute_input":"2022-07-15T18:19:16.261292Z","iopub.status.idle":"2022-07-15T18:19:16.556182Z","shell.execute_reply.started":"2022-07-15T18:19:16.261260Z","shell.execute_reply":"2022-07-15T18:19:16.555217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment = sentiment_analysis.SentimentAnalysisSpanish()","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:19:16.557380Z","iopub.execute_input":"2022-07-15T18:19:16.557616Z","iopub.status.idle":"2022-07-15T18:19:23.893889Z","shell.execute_reply.started":"2022-07-15T18:19:16.557595Z","shell.execute_reply":"2022-07-15T18:19:23.893259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numbers close to zero are negative\n# Numbers close to 1 are positive\n# Numbers close to 0.5 are neutral\n# Results made me think about: \"It's not what you say but how you say it\"\nprint(*[f'The sentence:\\t {sentence.text} has a sentiment of:\\t{sentiment.sentiment(sentence.text)}' for sentence in doc.sentences[20:30]], \n      sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:29:43.980114Z","iopub.execute_input":"2022-07-15T18:29:43.980434Z","iopub.status.idle":"2022-07-15T18:29:43.988969Z","shell.execute_reply.started":"2022-07-15T18:29:43.980411Z","shell.execute_reply":"2022-07-15T18:29:43.988329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment Analysis (Library #2)","metadata":{}},{"cell_type":"code","source":"!pip install pysentimiento","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:42:23.525212Z","iopub.execute_input":"2022-07-15T18:42:23.525534Z","iopub.status.idle":"2022-07-15T18:42:35.069797Z","shell.execute_reply.started":"2022-07-15T18:42:23.525510Z","shell.execute_reply":"2022-07-15T18:42:35.068936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pysentimiento import create_analyzer\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\")","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:42:50.268527Z","iopub.execute_input":"2022-07-15T18:42:50.268894Z","iopub.status.idle":"2022-07-15T18:43:01.778374Z","shell.execute_reply.started":"2022-07-15T18:42:50.268865Z","shell.execute_reply":"2022-07-15T18:43:01.776586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(*[f'The sentence:\\t {sentence.text} has a sentiment of:\\t{analyzer.predict(sentence.text)}' for sentence in doc.sentences[20:22]], \n      sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:48:16.610659Z","iopub.execute_input":"2022-07-15T18:48:16.610962Z","iopub.status.idle":"2022-07-15T18:48:16.778138Z","shell.execute_reply.started":"2022-07-15T18:48:16.610938Z","shell.execute_reply":"2022-07-15T18:48:16.777300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sentence in doc.sentences[20:30]:\n    analyzer_output_obj = analyzer.predict(sentence.text)\n    print(\"The sentence is: \",sentence.text,\"\\n\", analyzer_output_obj.probas)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:49:13.418882Z","iopub.execute_input":"2022-07-15T18:49:13.419248Z","iopub.status.idle":"2022-07-15T18:49:14.306399Z","shell.execute_reply.started":"2022-07-15T18:49:13.419220Z","shell.execute_reply":"2022-07-15T18:49:14.305369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:46:08.700796Z","iopub.execute_input":"2022-07-15T18:46:08.701156Z","iopub.status.idle":"2022-07-15T18:46:22.079160Z","shell.execute_reply.started":"2022-07-15T18:46:08.701130Z","shell.execute_reply":"2022-07-15T18:46:22.078483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[*print(f'')]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# can print the most likely emotion \nfor sentence in doc.sentences[20:30]:\n    analyzer_output_obj = emotion_analyzer.predict(sentence.text)\n    print(\"The sentence is: \", sentence.text,\"\\n\",\"The emotion is: \", analyzer_output_obj.output)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:52:03.818191Z","iopub.execute_input":"2022-07-15T18:52:03.818544Z","iopub.status.idle":"2022-07-15T18:52:04.764887Z","shell.execute_reply.started":"2022-07-15T18:52:03.818518Z","shell.execute_reply":"2022-07-15T18:52:04.762995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# can also output the probability of emotions\nfor sentence in doc.sentences[20:30]:\n    analyzer_output_obj = emotion_analyzer.predict(sentence.text)\n    print(\"The sentence is: \", sentence.text,\"\\n\",\"The emotion probabilities are\" analyzer_output_obj.probas)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:46:46.193150Z","iopub.execute_input":"2022-07-15T18:46:46.193477Z","iopub.status.idle":"2022-07-15T18:46:47.105089Z","shell.execute_reply.started":"2022-07-15T18:46:46.193453Z","shell.execute_reply":"2022-07-15T18:46:47.104492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HuggingFace (BigScience Bloom)","metadata":{}},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/quicktour","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:26:19.122030Z","iopub.execute_input":"2022-07-18T18:26:19.123110Z","iopub.status.idle":"2022-07-18T18:26:31.451490Z","shell.execute_reply.started":"2022-07-18T18:26:19.122973Z","shell.execute_reply":"2022-07-18T18:26:31.450005Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:26:31.454191Z","iopub.execute_input":"2022-07-18T18:26:31.455409Z","iopub.status.idle":"2022-07-18T18:27:14.283945Z","shell.execute_reply.started":"2022-07-18T18:26:31.455356Z","shell.execute_reply":"2022-07-18T18:27:14.282288Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:55:34.612011Z","iopub.execute_input":"2022-07-18T18:55:34.612546Z","iopub.status.idle":"2022-07-18T18:55:34.619945Z","shell.execute_reply.started":"2022-07-18T18:55:34.612505Z","shell.execute_reply":"2022-07-18T18:55:34.618409Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel, \nmodel_name = \"bigscience/bloom\"\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PyTorch\nfrom transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TensorFlow\nfrom transformers import TFAutoModelForSequenceClassification\nmodel = TFAutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_classifier(\"Yo te quiero, Puerto Rico.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# continue reading HuggingFace documentation - AutoClass section","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Two Approaches to Text Generation","metadata":{}},{"cell_type":"markdown","source":"## HuggingFace (DeepEsp GPT-2 Spanish)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Source: Huggingface.co The most important thing to remember though is you need to instantiate the tokenizer with the \n# same model name to ensure you’re using the same tokenization rules a model was pretrained with.\ntokenizer = AutoTokenizer.from_pretrained(\"DeepESP/gpt2-spanish\")\nmodel = AutoModelForCausalLM.from_pretrained(\"DeepESP/gpt2-spanish\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:28:49.662299Z","iopub.execute_input":"2022-07-18T18:28:49.664706Z","iopub.status.idle":"2022-07-18T18:29:14.339559Z","shell.execute_reply.started":"2022-07-18T18:28:49.664593Z","shell.execute_reply":"2022-07-18T18:29:14.337513Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## HuggingFace (Datificate GPT-2 Small Spanish)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"datificate/gpt2-small-spanish\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\"datificate/gpt2-small-spanish\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quick Tour","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:18:59.035257Z","iopub.execute_input":"2022-07-18T18:18:59.035716Z","iopub.status.idle":"2022-07-18T18:18:59.040005Z","shell.execute_reply.started":"2022-07-18T18:18:59.035667Z","shell.execute_reply":"2022-07-18T18:18:59.039133Z"}}},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:27:14.287100Z","iopub.execute_input":"2022-07-18T18:27:14.287657Z","iopub.status.idle":"2022-07-18T18:27:14.296306Z","shell.execute_reply.started":"2022-07-18T18:27:14.287598Z","shell.execute_reply":"2022-07-18T18:27:14.295025Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print([sentence.text for sentence in doc.sentences[4:6]])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:39.947364Z","iopub.execute_input":"2022-07-18T18:21:39.947840Z","iopub.status.idle":"2022-07-18T18:21:39.954904Z","shell.execute_reply.started":"2022-07-18T18:21:39.947801Z","shell.execute_reply":"2022-07-18T18:21:39.953616Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"encoding = tokenizer(\"Pase lo que pase no te voy a llamar.\")\nprint(encoding)\n\n# my_outputs = model(encoding)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:38:47.297919Z","iopub.execute_input":"2022-07-18T18:38:47.299019Z","iopub.status.idle":"2022-07-18T18:38:47.323929Z","shell.execute_reply.started":"2022-07-18T18:38:47.298968Z","shell.execute_reply":"2022-07-18T18:38:47.322565Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"generator = pipeline(\"text-generation\", model='DeepESP/gpt2-spanish', tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:45:21.400418Z","iopub.execute_input":"2022-07-18T18:45:21.401024Z","iopub.status.idle":"2022-07-18T18:45:25.029873Z","shell.execute_reply.started":"2022-07-18T18:45:21.400979Z","shell.execute_reply":"2022-07-18T18:45:25.028199Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/main_classes/text_generation\n# greedy decoding\nprompt = \"Pase lo que pase no te voy\"\ninput_ids = tokenizer(prompt, return_tensors='pt').input_ids\n\noutputs = model.generate(input_ids, do_sample=False, max_length=60)\ntokenizer.batch_decode(outputs, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:54:12.768804Z","iopub.execute_input":"2022-07-18T18:54:12.769271Z","iopub.status.idle":"2022-07-18T18:54:15.224236Z","shell.execute_reply.started":"2022-07-18T18:54:12.769236Z","shell.execute_reply":"2022-07-18T18:54:15.222801Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"Once your model is fine-tuned, you can save it with its tokenizer.","metadata":{}},{"cell_type":"markdown","source":"Resource: Continue Hugging Face Tutorials from [here](https://huggingface.co/docs/transformers/pipeline_tutorial).","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}