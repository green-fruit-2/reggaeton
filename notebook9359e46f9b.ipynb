{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-19T20:38:07.743761Z","iopub.execute_input":"2022-07-19T20:38:07.744383Z","iopub.status.idle":"2022-07-19T20:38:07.783791Z","shell.execute_reply.started":"2022-07-19T20:38:07.744268Z","shell.execute_reply":"2022-07-19T20:38:07.782712Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"lyrics = pd.read_csv(\"/kaggle/input/bad-bunny-lyrics/bad_bunny_lyrics.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.785869Z","iopub.execute_input":"2022-07-19T20:38:07.786185Z","iopub.status.idle":"2022-07-19T20:38:07.805441Z","shell.execute_reply.started":"2022-07-19T20:38:07.786153Z","shell.execute_reply":"2022-07-19T20:38:07.804633Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Good regex resource: https://realpython.com/regex-python/#python-regex-metacharacters\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.806899Z","iopub.execute_input":"2022-07-19T20:38:07.807121Z","iopub.status.idle":"2022-07-19T20:38:07.811053Z","shell.execute_reply.started":"2022-07-19T20:38:07.807098Z","shell.execute_reply":"2022-07-19T20:38:07.810132Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# practice_str = '[Letra de \"NI BIEN NI MAL\"]  [Intro: Bad Bunny] Yeh-yeh Yeh-yeh Yeh-yeh'\npractice_song_lyric = lyrics.iloc[0,4]\npractice_song_lyric","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.816148Z","iopub.execute_input":"2022-07-19T20:38:07.816637Z","iopub.status.idle":"2022-07-19T20:38:07.826468Z","shell.execute_reply.started":"2022-07-19T20:38:07.816612Z","shell.execute_reply":"2022-07-19T20:38:07.825412Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(practice_song_lyric)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.836066Z","iopub.execute_input":"2022-07-19T20:38:07.836583Z","iopub.status.idle":"2022-07-19T20:38:07.841520Z","shell.execute_reply.started":"2022-07-19T20:38:07.836553Z","shell.execute_reply":"2022-07-19T20:38:07.840580Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Source: https://stackoverflow.com/questions/65022050/cleaning-song-lyrics-with-regex","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.848577Z","iopub.execute_input":"2022-07-19T20:38:07.849116Z","iopub.status.idle":"2022-07-19T20:38:07.852264Z","shell.execute_reply.started":"2022-07-19T20:38:07.849089Z","shell.execute_reply":"2022-07-19T20:38:07.851630Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# removed brackets used to denote sections of song\n# removed new lines and added periods for sentence tokenization\nremoved_brackets = re.sub(r\"[\\[].*?[\\]]\",\"\",practice_song_lyric)\nno_brackets_or_new_lines = re.sub(r\"\\n{2}\",\"\",removed_brackets)\nno_brackets_or_new_lines = re.sub(r\"[\\n]\",\". \",no_brackets_or_new_lines)\nprint(no_brackets_or_new_lines)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.862804Z","iopub.execute_input":"2022-07-19T20:38:07.863079Z","iopub.status.idle":"2022-07-19T20:38:07.868804Z","shell.execute_reply.started":"2022-07-19T20:38:07.863057Z","shell.execute_reply":"2022-07-19T20:38:07.867866Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# might need to replace new lines with periods\ncorrect_vas = re.sub(r\"va\\'\",\"vas\",no_brackets_or_new_lines)\ncorrect_para_zero = re.sub(r\"Pa\\'l\",\"Para el\",correct_vas)\ncorrect_para = re.sub(r\"Pa\\'\",\"Para \",correct_para_zero)\ncorrect_voy = re.sub(r\"vo\\'\",\"voy \",correct_para)\ncorrect_para_2 = re.sub(r\"pa\\'\",\"para\",correct_voy)\ncorrect_de = re.sub(r\"\\'e\",\"de\",correct_para_2)\ncorrect_puyas = re.sub(r\"puya\\'\",\"puyas\",correct_de)\ncorrect_puyas += '.'\ncorrect_puyas","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.881306Z","iopub.execute_input":"2022-07-19T20:38:07.881569Z","iopub.status.idle":"2022-07-19T20:38:07.890432Z","shell.execute_reply.started":"2022-07-19T20:38:07.881547Z","shell.execute_reply":"2022-07-19T20:38:07.889253Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip install stanza ","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:07.906026Z","iopub.execute_input":"2022-07-19T20:38:07.906995Z","iopub.status.idle":"2022-07-19T20:38:21.823115Z","shell.execute_reply.started":"2022-07-19T20:38:07.906933Z","shell.execute_reply":"2022-07-19T20:38:21.822431Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Source: https://stanfordnlp.github.io/stanza/\n# Source: https://stanfordnlp.github.io/stanza/tokenize.html#:~:text=Training%2DOnly%20Options-,Description,invoked%20by%20the%20name%20tokenize%20.\n# Note: Stanza does not offer a Spanish Sentiment Analyzer\n# Check out Stanza's other sections like:\n# - Pipeline and Processors\n# - Part-of-Speech and Morphological Features\n# - Lemmatization\nimport stanza","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:21.824302Z","iopub.execute_input":"2022-07-19T20:38:21.824539Z","iopub.status.idle":"2022-07-19T20:38:31.195224Z","shell.execute_reply.started":"2022-07-19T20:38:21.824516Z","shell.execute_reply":"2022-07-19T20:38:31.194214Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"stanza.download('es', package='ancora', processors='tokenize,mwt,pos,lemma', verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:31.196434Z","iopub.execute_input":"2022-07-19T20:38:31.197116Z","iopub.status.idle":"2022-07-19T20:38:59.558580Z","shell.execute_reply.started":"2022-07-19T20:38:31.197094Z","shell.execute_reply":"2022-07-19T20:38:59.557711Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma', lang='es', use_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:38:59.561061Z","iopub.execute_input":"2022-07-19T20:38:59.561384Z","iopub.status.idle":"2022-07-19T20:39:00.399837Z","shell.execute_reply.started":"2022-07-19T20:38:59.561356Z","shell.execute_reply":"2022-07-19T20:39:00.399049Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"doc = stNLP('Barack Obama nació en Hawaii.')\nprint(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:39:00.400837Z","iopub.execute_input":"2022-07-19T20:39:00.401056Z","iopub.status.idle":"2022-07-19T20:39:00.489828Z","shell.execute_reply.started":"2022-07-19T20:39:00.401035Z","shell.execute_reply":"2022-07-19T20:39:00.489199Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Source: https://stanfordnlp.github.io/stanza/tokenize.html#:~:text=Training%2DOnly%20Options-,Description,invoked%20by%20the%20name%20tokenize%20.\n# tokenization and sentence segmentation performed\ndoc = stNLP(correct_puyas)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:39:00.491039Z","iopub.execute_input":"2022-07-19T20:39:00.491249Z","iopub.status.idle":"2022-07-19T20:39:01.386404Z","shell.execute_reply.started":"2022-07-19T20:39:00.491227Z","shell.execute_reply":"2022-07-19T20:39:01.385652Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences[4:6] for word in sent.words], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:22.248066Z","iopub.execute_input":"2022-07-18T18:21:22.248656Z","iopub.status.idle":"2022-07-18T18:21:22.255340Z","shell.execute_reply.started":"2022-07-18T18:21:22.248621Z","shell.execute_reply":"2022-07-18T18:21:22.254280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, sentence in enumerate(doc.sentences[4:6]):\n    print(f'====== Sentence {i+1} tokens =======')\n    print(*[f'id: {token.id}\\ttext: {token.text}' for token in sentence.tokens], sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:22.256830Z","iopub.execute_input":"2022-07-18T18:21:22.257962Z","iopub.status.idle":"2022-07-18T18:21:22.272129Z","shell.execute_reply.started":"2022-07-18T18:21:22.257924Z","shell.execute_reply":"2022-07-18T18:21:22.270629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print([sentence.text for sentence in doc.sentences[4:6]])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:21:22.273950Z","iopub.execute_input":"2022-07-18T18:21:22.275350Z","iopub.status.idle":"2022-07-18T18:21:22.290457Z","shell.execute_reply.started":"2022-07-18T18:21:22.275142Z","shell.execute_reply":"2022-07-18T18:21:22.289206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc.sentences[4:5]","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:15.300856Z","iopub.execute_input":"2022-07-15T18:18:15.301281Z","iopub.status.idle":"2022-07-15T18:18:15.311779Z","shell.execute_reply.started":"2022-07-15T18:18:15.301258Z","shell.execute_reply":"2022-07-15T18:18:15.310914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replaces all Unicode whitespace (such as \\u) with a single space\n#re.sub(\"\\s+\", \" \", lyric, flags=re.UNICODE)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:15.312888Z","iopub.execute_input":"2022-07-15T18:18:15.314163Z","iopub.status.idle":"2022-07-15T18:18:15.320770Z","shell.execute_reply.started":"2022-07-15T18:18:15.314116Z","shell.execute_reply":"2022-07-15T18:18:15.319868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spanish word normalization Python packages and libraries (Cucco)\n# ftfy - handles mojibake","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:15.321852Z","iopub.execute_input":"2022-07-15T18:18:15.322556Z","iopub.status.idle":"2022-07-15T18:18:15.331485Z","shell.execute_reply.started":"2022-07-15T18:18:15.322527Z","shell.execute_reply":"2022-07-15T18:18:15.330476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0. Sentence Tokenization - nltk package (tokenize and FreqDist)\n0. Finding semantically related words using word embeddings (already loadded the dataset)\n    * Look at Google Colab book on word2vec to see an example of how to do this\n0. Spanish lemmatizer - https://stackoverflow.com/questions/60534999/how-to-solve-spanish-lemmatization-problems-with-spacy\n    * The link above has sources that show how to make your own lemmatizer, FreeLing (provides lemmatization in Spanish and other languages), and spacy-stanza (\"spaCy's API with the Stanza's models\")\n    * https://github.com/pablodms/spacy-spanish-lemmatizer    \n    * pattern is another library\n0. Word Cloud\n1. **Topic Modeling** - can later let the user generate songs based on a topic\n    * This might use zero-shot classification (which can be done in Hugging Face)\n2. **Sentiment Analysis** - user can create songs with a specific sentiment\n    * Another option for sentiment analysis: using pysentimiento for emotion analysis (in addition to sentiment analysis)\n    * Another option for sentiment analysis: using Big Science Bloom\n3. **Text Generation**\n    * Two GPT-2 Models\n3. Learn how to Use Kaggle Console effectively for projects\n4. **Quick Tour on HuggingFace Transformers**\n    * https://huggingface.co/docs/transformers/quicktour\n5. **Getting Started with HuggingFace**\n    * https://www.youtube.com/watch?v=QEaBAZQCtwE&t=120s","metadata":{}},{"cell_type":"markdown","source":"* How to track Jupyter notebook changes in GitHub - https://blog.reviewnb.com/jupyter-notebook-on-github-oss-examples/\n* Top 8 Python libraries for NLP - https://www.analyticsvidhya.com/blog/2021/05/top-8-python-libraries-for-natural-language-processing-nlp-in-2021/","metadata":{}},{"cell_type":"markdown","source":"# Sentiment Analysis (Library #1)","metadata":{}},{"cell_type":"code","source":"!pip install sentiment-analysis-spanish\n!pip install keras tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:18:37.551851Z","iopub.execute_input":"2022-07-15T18:18:37.552208Z","iopub.status.idle":"2022-07-15T18:19:16.258224Z","shell.execute_reply.started":"2022-07-15T18:18:37.552179Z","shell.execute_reply":"2022-07-15T18:19:16.257115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentiment_analysis_spanish import sentiment_analysis","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:19:16.260857Z","iopub.execute_input":"2022-07-15T18:19:16.261292Z","iopub.status.idle":"2022-07-15T18:19:16.556182Z","shell.execute_reply.started":"2022-07-15T18:19:16.261260Z","shell.execute_reply":"2022-07-15T18:19:16.555217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment = sentiment_analysis.SentimentAnalysisSpanish()","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:19:16.557380Z","iopub.execute_input":"2022-07-15T18:19:16.557616Z","iopub.status.idle":"2022-07-15T18:19:23.893889Z","shell.execute_reply.started":"2022-07-15T18:19:16.557595Z","shell.execute_reply":"2022-07-15T18:19:23.893259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numbers close to zero are negative\n# Numbers close to 1 are positive\n# Numbers close to 0.5 are neutral\n# Results made me think about: \"It's not what you say but how you say it\"\nprint(*[f'The sentence:\\t {sentence.text} has a sentiment of:\\t{sentiment.sentiment(sentence.text)}' for sentence in doc.sentences[20:30]], \n      sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:29:43.980114Z","iopub.execute_input":"2022-07-15T18:29:43.980434Z","iopub.status.idle":"2022-07-15T18:29:43.988969Z","shell.execute_reply.started":"2022-07-15T18:29:43.980411Z","shell.execute_reply":"2022-07-15T18:29:43.988329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment Analysis (Library #2)","metadata":{}},{"cell_type":"code","source":"!pip install pysentimiento","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:42:23.525212Z","iopub.execute_input":"2022-07-15T18:42:23.525534Z","iopub.status.idle":"2022-07-15T18:42:35.069797Z","shell.execute_reply.started":"2022-07-15T18:42:23.525510Z","shell.execute_reply":"2022-07-15T18:42:35.068936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pysentimiento import create_analyzer\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\")","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:42:50.268527Z","iopub.execute_input":"2022-07-15T18:42:50.268894Z","iopub.status.idle":"2022-07-15T18:43:01.778374Z","shell.execute_reply.started":"2022-07-15T18:42:50.268865Z","shell.execute_reply":"2022-07-15T18:43:01.776586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(*[f'The sentence:\\t {sentence.text} has a sentiment of:\\t{analyzer.predict(sentence.text)}' for sentence in doc.sentences[20:22]], \n      sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:48:16.610659Z","iopub.execute_input":"2022-07-15T18:48:16.610962Z","iopub.status.idle":"2022-07-15T18:48:16.778138Z","shell.execute_reply.started":"2022-07-15T18:48:16.610938Z","shell.execute_reply":"2022-07-15T18:48:16.777300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sentence in doc.sentences[20:30]:\n    analyzer_output_obj = analyzer.predict(sentence.text)\n    print(\"The sentence is: \",sentence.text,\"\\n\", analyzer_output_obj.probas)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:49:13.418882Z","iopub.execute_input":"2022-07-15T18:49:13.419248Z","iopub.status.idle":"2022-07-15T18:49:14.306399Z","shell.execute_reply.started":"2022-07-15T18:49:13.419220Z","shell.execute_reply":"2022-07-15T18:49:14.305369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"es\")","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:46:08.700796Z","iopub.execute_input":"2022-07-15T18:46:08.701156Z","iopub.status.idle":"2022-07-15T18:46:22.079160Z","shell.execute_reply.started":"2022-07-15T18:46:08.701130Z","shell.execute_reply":"2022-07-15T18:46:22.078483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# can print the most likely emotion \nfor sentence in doc.sentences[20:30]:\n    analyzer_output_obj = emotion_analyzer.predict(sentence.text)\n    print(\"The sentence is: \", sentence.text,\"\\n\",\"The emotion is: \", analyzer_output_obj.output)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:52:03.818191Z","iopub.execute_input":"2022-07-15T18:52:03.818544Z","iopub.status.idle":"2022-07-15T18:52:04.764887Z","shell.execute_reply.started":"2022-07-15T18:52:03.818518Z","shell.execute_reply":"2022-07-15T18:52:04.762995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# can also output the probability of emotions\nfor sentence in doc.sentences[20:30]:\n    analyzer_output_obj = emotion_analyzer.predict(sentence.text)\n    print(\"The sentence is: \", sentence.text,\"\\n\",\"The emotion probabilities are\" analyzer_output_obj.probas)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T18:46:46.193150Z","iopub.execute_input":"2022-07-15T18:46:46.193477Z","iopub.status.idle":"2022-07-15T18:46:47.105089Z","shell.execute_reply.started":"2022-07-15T18:46:46.193453Z","shell.execute_reply":"2022-07-15T18:46:47.104492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HuggingFace (BigScience Bloom)","metadata":{}},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/quicktour","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:39:01.387374Z","iopub.execute_input":"2022-07-19T20:39:01.387588Z","iopub.status.idle":"2022-07-19T20:39:10.956012Z","shell.execute_reply.started":"2022-07-19T20:39:01.387567Z","shell.execute_reply":"2022-07-19T20:39:10.954747Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:39:10.957529Z","iopub.execute_input":"2022-07-19T20:39:10.958454Z","iopub.status.idle":"2022-07-19T20:39:42.314252Z","shell.execute_reply.started":"2022-07-19T20:39:10.958404Z","shell.execute_reply":"2022-07-19T20:39:42.313593Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:39:42.315703Z","iopub.execute_input":"2022-07-19T20:39:42.316031Z","iopub.status.idle":"2022-07-19T20:39:45.077715Z","shell.execute_reply.started":"2022-07-19T20:39:42.315995Z","shell.execute_reply":"2022-07-19T20:39:45.076750Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel, \nmodel_name = \"bigscience/bloom\"\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PyTorch\nfrom transformers import AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TensorFlow\nfrom transformers import TFAutoModelForSequenceClassification\nmodel = TFAutoModelForSequenceClassification.from_pretrained(model_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment_classifier(\"Yo te quiero, Puerto Rico.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# continue reading HuggingFace documentation - AutoClass section","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Two Approaches to Text Generation","metadata":{}},{"cell_type":"markdown","source":"## HuggingFace (DeepEsp GPT-2 Spanish)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Source: Huggingface.co The most important thing to remember though is you need to instantiate the tokenizer with the \n# same model name to ensure you’re using the same tokenization rules a model was pretrained with.\n# So, use the pretrained model's associated pretrained tokenizer - This ensures the text is split the \n# same way as the pretraining corpus, and uses the same corresponding tokens-to-index \n# (usually referrred to as the vocab) during pretraining.\n\n# the AutoTokenizer method also calls the vocab\ntokenizer = AutoTokenizer.from_pretrained(\"DeepESP/gpt2-spanish\")\nmodel = AutoModelForCausalLM.from_pretrained(\"DeepESP/gpt2-spanish\")","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:39:45.082030Z","iopub.execute_input":"2022-07-19T20:39:45.082785Z","iopub.status.idle":"2022-07-19T20:40:23.455062Z","shell.execute_reply.started":"2022-07-19T20:39:45.082747Z","shell.execute_reply":"2022-07-19T20:40:23.454045Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## HuggingFace (Datificate GPT-2 Small Spanish)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"datificate/gpt2-small-spanish\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\"datificate/gpt2-small-spanish\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quick Tour","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:18:59.035257Z","iopub.execute_input":"2022-07-18T18:18:59.035716Z","iopub.status.idle":"2022-07-18T18:18:59.040005Z","shell.execute_reply.started":"2022-07-18T18:18:59.035667Z","shell.execute_reply":"2022-07-18T18:18:59.039133Z"}}},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:40:23.456331Z","iopub.execute_input":"2022-07-19T20:40:23.456608Z","iopub.status.idle":"2022-07-19T20:40:23.460996Z","shell.execute_reply.started":"2022-07-19T20:40:23.456581Z","shell.execute_reply":"2022-07-19T20:40:23.460090Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print([sentence.text for sentence in doc.sentences[4:7]])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:56:21.983847Z","iopub.execute_input":"2022-07-19T20:56:21.984668Z","iopub.status.idle":"2022-07-19T20:56:21.990668Z","shell.execute_reply.started":"2022-07-19T20:56:21.984637Z","shell.execute_reply":"2022-07-19T20:56:21.989711Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"example_list_of_sentences = [sentence.text for sentence in doc.sentences[4:7]]","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:56:42.146578Z","iopub.execute_input":"2022-07-19T20:56:42.146873Z","iopub.status.idle":"2022-07-19T20:56:42.150752Z","shell.execute_reply.started":"2022-07-19T20:56:42.146843Z","shell.execute_reply":"2022-07-19T20:56:42.149904Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# sentences that are not the longest sentence are padded with zeroes (see 'attention_mask' key)\n# the tensors are fed into the model\nencoding = tokenizer(example_list_of_sentences, padding=True, return_tensors='pt')\nprint(encoding)\n\n# my_outputs = model(encoding)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:59:48.353241Z","iopub.execute_input":"2022-07-19T20:59:48.353556Z","iopub.status.idle":"2022-07-19T20:59:48.360128Z","shell.execute_reply.started":"2022-07-19T20:59:48.353534Z","shell.execute_reply":"2022-07-19T20:59:48.359338Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# decoding the input_ids to return to the original input\ntokenizer.decode(encoding['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:54:45.366530Z","iopub.execute_input":"2022-07-19T20:54:45.366871Z","iopub.status.idle":"2022-07-19T20:54:46.439799Z","shell.execute_reply.started":"2022-07-19T20:54:45.366843Z","shell.execute_reply":"2022-07-19T20:54:46.438920Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# currently not used in making the text predictions below\ngenerator = pipeline(\"text-generation\", model='DeepESP/gpt2-spanish', tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T20:40:23.495138Z","iopub.execute_input":"2022-07-19T20:40:23.495624Z","iopub.status.idle":"2022-07-19T20:40:28.509785Z","shell.execute_reply.started":"2022-07-19T20:40:23.495601Z","shell.execute_reply":"2022-07-19T20:40:28.508778Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"generator(\"Pase lo que pase no te voy\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/main_classes/text_generation\n# greedy decoding\nprompt = \"Pase lo que pase no te voy\"\ninput_ids = tokenizer(prompt, return_tensors='pt').input_ids\n\noutputs = model.generate(input_ids, do_sample=False, max_length=60)\ntokenizer.batch_decode(outputs, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T18:54:12.768804Z","iopub.execute_input":"2022-07-18T18:54:12.769271Z","iopub.status.idle":"2022-07-18T18:54:15.224236Z","shell.execute_reply.started":"2022-07-18T18:54:12.769236Z","shell.execute_reply":"2022-07-18T18:54:15.222801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once your model is fine-tuned, you can save it with its tokenizer.","metadata":{}},{"cell_type":"markdown","source":"Resource: Continue Hugging Face Tutorials from [here](https://huggingface.co/docs/transformers/training).\n\nSpanish text-to-speech [model](https://huggingface.co/facebook/tts_transformer-es-css10) ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}